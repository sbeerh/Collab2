{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbeerh/Collab2/blob/main/Copy_of_transfer_learning_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfh8tpTFS9Mv"
      },
      "source": [
        "# **Transfer Learning: Vision Transformers**\n",
        "## **Image Classification**\n",
        "\n",
        "---\n",
        "\n",
        "Transfer learning is a technique where a pre-trained model, which has already learned features from one task, is used as the starting point for a similar task. This saves time and resources by leveraging the existing knowledge of the model instead of training a new model from scratch.\n",
        "\n",
        "In this tutorial, we will be looking at how we can apply transfer learning for image classification with a Vision Transformer on any dataset of our choice.\n",
        "\n",
        "In transfer learning, we do not need to update the parameters of the entire model. Since our ViT has learned feature representations from millions of images, we can just choose to train the very last layers of our model to make it perform well on our new dataset.\n",
        "\n",
        "For this tutorial, we will be using [google/vit-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224) model from the Hugging Face hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdBfBalXS9Mw"
      },
      "source": [
        "### Let's begin by importing some necessary modules and functions\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:28.765539Z",
          "iopub.status.busy": "2023-12-14T19:33:28.764870Z",
          "iopub.status.idle": "2023-12-14T19:33:40.617086Z",
          "shell.execute_reply": "2023-12-14T19:33:40.615827Z",
          "shell.execute_reply.started": "2023-12-14T19:33:28.765494Z"
        },
        "id": "HEwiQlT3S9Mx"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:40.620106Z",
          "iopub.status.busy": "2023-12-14T19:33:40.619322Z",
          "iopub.status.idle": "2023-12-14T19:33:47.299161Z",
          "shell.execute_reply": "2023-12-14T19:33:47.298218Z",
          "shell.execute_reply.started": "2023-12-14T19:33:40.620063Z"
        },
        "id": "GCdKLbahS9Mx"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "from transformers import AutoImageProcessor, ViTForImageClassification\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:47.301085Z",
          "iopub.status.busy": "2023-12-14T19:33:47.300396Z",
          "iopub.status.idle": "2023-12-14T19:33:47.323947Z",
          "shell.execute_reply": "2023-12-14T19:33:47.323048Z",
          "shell.execute_reply.started": "2023-12-14T19:33:47.301054Z"
        },
        "id": "d2WXhBFGS9My"
      },
      "outputs": [],
      "source": [
        "# Login onto Hugging Face hub to load any private dataset/model.\n",
        "# We need to login as we'll also upload our model to the hub\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j684N-fnS9My"
      },
      "source": [
        "### Now, let's load our image classification dataset\n",
        "---\n",
        "\n",
        "For this tutorial, we'll be using [Oxford-IIIT Pets Dataset](https://huggingface.co/datasets/pcuenq/oxford-pets). It is a collection of 37 different cat and dog breed images. We'll be using [Hugging Face Datasets](https://huggingface.co/datasets) library to load our dataset easily from the hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:47.326671Z",
          "iopub.status.busy": "2023-12-14T19:33:47.326334Z",
          "iopub.status.idle": "2023-12-14T19:33:47.877186Z",
          "shell.execute_reply": "2023-12-14T19:33:47.876350Z",
          "shell.execute_reply.started": "2023-12-14T19:33:47.326645Z"
        },
        "id": "VIQNXo59S9My"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('pcuenq/oxford-pets')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dsvebWjS9My"
      },
      "source": [
        "#### The dataset contains the following features:\n",
        "\n",
        "- path: a path to the file\n",
        "- label: the breed of the animal\n",
        "- dog: indicates if the animal is a dog or not\n",
        "- image: the raw image data stored as bytes, which can be converted into formats like PIL Image for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:47.878564Z",
          "iopub.status.busy": "2023-12-14T19:33:47.878295Z",
          "iopub.status.idle": "2023-12-14T19:33:47.889357Z",
          "shell.execute_reply": "2023-12-14T19:33:47.888458Z",
          "shell.execute_reply.started": "2023-12-14T19:33:47.878538Z"
        },
        "id": "bMLPnVcfS9Mz"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:47.890747Z",
          "iopub.status.busy": "2023-12-14T19:33:47.890461Z",
          "iopub.status.idle": "2023-12-14T19:33:47.904441Z",
          "shell.execute_reply": "2023-12-14T19:33:47.903490Z",
          "shell.execute_reply.started": "2023-12-14T19:33:47.890723Z"
        },
        "id": "6klFGI-bS9Mz"
      },
      "outputs": [],
      "source": [
        "labels = dataset['train'].unique('label')\n",
        "print(len(labels),labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7K5J7pJS9Mz"
      },
      "source": [
        "#### Let's see some sample images from our dataset\n",
        "---\n",
        "\n",
        "For any dataset we use with the `datasets` library, we can shuffle the dataset using `shuffle()` and, select any samples using the `select()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:47.906134Z",
          "iopub.status.busy": "2023-12-14T19:33:47.905550Z",
          "iopub.status.idle": "2023-12-14T19:33:50.212776Z",
          "shell.execute_reply": "2023-12-14T19:33:50.211548Z",
          "shell.execute_reply.started": "2023-12-14T19:33:47.906099Z"
        },
        "id": "vlYIliGGS9Mz"
      },
      "outputs": [],
      "source": [
        "def show_samples(ds,rows,cols):\n",
        "    samples = ds.shuffle().select(np.arange(rows*cols)) # selecting random images\n",
        "    fig = plt.figure(figsize=(cols*4,rows*4))\n",
        "    # plotting\n",
        "    for i in range(rows*cols):\n",
        "        img = samples[i]['image']\n",
        "        label = samples[i]['label']\n",
        "        fig.add_subplot(rows,cols,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "\n",
        "show_samples(dataset['train'],rows=3,cols=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5x2c-BqS9Mz"
      },
      "source": [
        "## Preprocessing our dataset\n",
        "---\n",
        "\n",
        "When it comes to image datasets, preprocessing involves multiple steps. This includes transforms such as resizing all images to have the same dimensions, normalizing, and scaling the pixel values to a uniform range. We can also add augmentations to our images like random flips, rotations, perspectives, etc.\n",
        "\n",
        "Before we apply our transforms, let's split our dataset into 3 parts for training, validation  and a hidden test set to evaluate how our model performs. We can use the in-built `train_test_split` method to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgi9338vS9Mz"
      },
      "source": [
        "Since we only have a `train` split in our original dataset, we'll use 80% of it for training and 10% for `validation` and remaining 10% as our `test` split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.214473Z",
          "iopub.status.busy": "2023-12-14T19:33:50.214136Z",
          "iopub.status.idle": "2023-12-14T19:33:50.239226Z",
          "shell.execute_reply": "2023-12-14T19:33:50.238184Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.214443Z"
        },
        "id": "pCb2Oy3WS9Mz"
      },
      "outputs": [],
      "source": [
        "split_dataset = dataset['train'].train_test_split(test_size=0.2) # 80% train, 20% evaluation\n",
        "eval_dataset = split_dataset['test'].train_test_split(test_size=0.5) # 50% validation, 50% test\n",
        "\n",
        "# recombining the splits using a DatasetDict\n",
        "\n",
        "our_dataset = DatasetDict({\n",
        "    'train': split_dataset['train'],\n",
        "    'validation': eval_dataset['train'],\n",
        "    'test': eval_dataset['test']\n",
        "})\n",
        "\n",
        "our_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsDh2JXbS9Mz"
      },
      "source": [
        "It is important to note that any model cannot understand the labels in their `string` format. Hence, we map them to their integer counterparts. Since there are 37 labels, the labels will be mapped to a number from 0 to 36.\n",
        "\n",
        "We'll create two mappings, `label2id` and `id2label` to convert the labels to their IDs and vice versa. This is also be useful when we initialize our model to update its configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.240736Z",
          "iopub.status.busy": "2023-12-14T19:33:50.240463Z",
          "iopub.status.idle": "2023-12-14T19:33:50.245584Z",
          "shell.execute_reply": "2023-12-14T19:33:50.244683Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.240710Z"
        },
        "id": "kmYi5Tz6S9Mz"
      },
      "outputs": [],
      "source": [
        "label2id = {c:idx for idx,c in enumerate(labels)}\n",
        "id2label = {idx:c for idx,c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxaIKlSQS9Mz"
      },
      "source": [
        "### Image Processor\n",
        "\n",
        "To apply the right transforms on our images, we will be using [AutoImageProcessor](https://huggingface.co/docs/transformers/main_classes/image_processor) which will apply the transforms according to the model we will use. We can check its configuration to see what transforms will be applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.249210Z",
          "iopub.status.busy": "2023-12-14T19:33:50.248945Z",
          "iopub.status.idle": "2023-12-14T19:33:50.424110Z",
          "shell.execute_reply": "2023-12-14T19:33:50.423300Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.249185Z"
        },
        "id": "HtRNRlfrS9Mz"
      },
      "outputs": [],
      "source": [
        "processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "processor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF-okisbS9M0"
      },
      "source": [
        "To apply the transforms to a batch at the time of training, we can create a function which will preprocess the batch. The trainer will call this function when we add it to the dataset using `with_transform`.\n",
        "\n",
        "At the time of training, we need to apply the transforms on a batch of samples. To handle the batches, we'll create a `transforms` function which will take care of the following:\n",
        "\n",
        "- Converting all images into RGB: It might be possible that some images in your dataset will be grayscale or transparent (RGBA).\n",
        "- Converting the string labels to integers: using the `label2id` map.\n",
        "- Applying image transforms: we pass the images through the `processor` to process, and convert them into PyTorch format.\n",
        "\n",
        "The resultant dataset features will be:\n",
        "```py\n",
        "{\n",
        "    'pixel_values': torch.Tensor,\n",
        "    'labels': List\n",
        "}\n",
        "```\n",
        "\n",
        "We'll pair the function with our dataset using the `with_transform()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.425695Z",
          "iopub.status.busy": "2023-12-14T19:33:50.425400Z",
          "iopub.status.idle": "2023-12-14T19:33:50.430722Z",
          "shell.execute_reply": "2023-12-14T19:33:50.429811Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.425669Z"
        },
        "id": "8U40ZRkgS9M0"
      },
      "outputs": [],
      "source": [
        "def transforms(batch):\n",
        "    # Check if the input is a list of dictionaries (containing 'bytes') or a list of PIL Images\n",
        "    if isinstance(batch['image'][0], dict) and 'bytes' in batch['image'][0]:\n",
        "        batch['image'] = [Image.open(io.BytesIO(x['bytes'])).convert('RGB') for x in batch['image']]\n",
        "    elif isinstance(batch['image'][0], Image.Image):\n",
        "        batch['image'] = [x.convert('RGB') for x in batch['image']]\n",
        "    else:\n",
        "        raise TypeError(\"Unsupported image format in batch['image']\")\n",
        "\n",
        "    inputs = processor(batch['image'],return_tensors='pt')\n",
        "    inputs['labels']=[label2id[y] for y in batch['label']]\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.432519Z",
          "iopub.status.busy": "2023-12-14T19:33:50.432145Z",
          "iopub.status.idle": "2023-12-14T19:33:50.445860Z",
          "shell.execute_reply": "2023-12-14T19:33:50.445044Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.432485Z"
        },
        "id": "TmNtn7P1S9M0"
      },
      "outputs": [],
      "source": [
        "processed_dataset = our_dataset.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPpWrOgLS9M0"
      },
      "source": [
        "#### Data Collation\n",
        "\n",
        "Batching our data in the correct format is collation. For `pixel_values`, the input shape for the model should be `(batch, channels, height, width)` and for `labels`, the shape should be `(batch,)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.447700Z",
          "iopub.status.busy": "2023-12-14T19:33:50.446942Z",
          "iopub.status.idle": "2023-12-14T19:33:50.454701Z",
          "shell.execute_reply": "2023-12-14T19:33:50.453863Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.447665Z"
        },
        "id": "mym3Mi4pS9M0"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['labels'] for x in batch])\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yldat3s-S9M0"
      },
      "source": [
        "## Let's see how to calculate the metrics\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9pWG8PGS9M0"
      },
      "source": [
        "We can use Hugging Face `evaluate` library to calculate the metrics. For image classification, we can use the accuracy metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.456075Z",
          "iopub.status.busy": "2023-12-14T19:33:50.455834Z",
          "iopub.status.idle": "2023-12-14T19:33:50.881540Z",
          "shell.execute_reply": "2023-12-14T19:33:50.880713Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.456053Z"
        },
        "id": "3SjsAcV3S9M0"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load('accuracy')\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits,axis=1)\n",
        "    score = accuracy.compute(predictions=predictions, references=labels)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_T4mECjS9M0"
      },
      "source": [
        "## Loading our Model\n",
        "---\n",
        "\n",
        "We will use [ViTForImageClassification](https://huggingface.co/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification) to load our pre-trained model.\n",
        "\n",
        "We do need to update the final classification layer, to output predictions equal to the number of labels in our dataset.\n",
        "We will do that by passing in `num_labels` argument along with our label mappings `id2label` and `label2id`.\n",
        "\n",
        "We also need to pass `ignore_mismatched_sizes = True` to compensate for the change in number of parameters in the classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:50.882812Z",
          "iopub.status.busy": "2023-12-14T19:33:50.882548Z",
          "iopub.status.idle": "2023-12-14T19:33:51.891081Z",
          "shell.execute_reply": "2023-12-14T19:33:51.890292Z",
          "shell.execute_reply.started": "2023-12-14T19:33:50.882787Z"
        },
        "id": "tTSQkVWaS9M0"
      },
      "outputs": [],
      "source": [
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224',\n",
        "    num_labels = len(labels),\n",
        "    id2label = id2label,\n",
        "    label2id = label2id,\n",
        "    ignore_mismatched_sizes = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQ4dZJmS9M0"
      },
      "source": [
        "#### Here's the architecture of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:51.892839Z",
          "iopub.status.busy": "2023-12-14T19:33:51.892468Z",
          "iopub.status.idle": "2023-12-14T19:33:51.900819Z",
          "shell.execute_reply": "2023-12-14T19:33:51.899960Z",
          "shell.execute_reply.started": "2023-12-14T19:33:51.892802Z"
        },
        "id": "RhbNkkTqS9M0"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSu5DCvJS9M0"
      },
      "source": [
        "Since we are not going to update the entire model, we can \"freeze\" all the parameters except for the new `classifier` layer by setting `requires_grad` to False for each layer's parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:51.902421Z",
          "iopub.status.busy": "2023-12-14T19:33:51.902042Z",
          "iopub.status.idle": "2023-12-14T19:33:51.911121Z",
          "shell.execute_reply": "2023-12-14T19:33:51.910299Z",
          "shell.execute_reply.started": "2023-12-14T19:33:51.902387Z"
        },
        "id": "ymFiybsyS9M0"
      },
      "outputs": [],
      "source": [
        "for name,p in model.named_parameters():\n",
        "    if not name.startswith('classifier'):\n",
        "        p.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq0jk2duS9M0"
      },
      "source": [
        "We can check how many parameters are there in the model along with how many are actually going to be trained now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:51.912589Z",
          "iopub.status.busy": "2023-12-14T19:33:51.912323Z",
          "iopub.status.idle": "2023-12-14T19:33:51.926652Z",
          "shell.execute_reply": "2023-12-14T19:33:51.925796Z",
          "shell.execute_reply.started": "2023-12-14T19:33:51.912565Z"
        },
        "id": "s0bNrtOIS9M0"
      },
      "outputs": [],
      "source": [
        "num_params = sum([p.numel() for p in model.parameters()])\n",
        "trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "\n",
        "print(f\"{num_params = :,} | {trainable_params = :,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9kL4sU8S9M0"
      },
      "source": [
        "# Let's commence our training 🚀️🚀️🚀️\n",
        "---\n",
        "\n",
        "We'll be using [Hugging Face Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer) to train our model. Feel free to choose your training arguments such as the batch size, learning rate, number of epochs, logging options, etc.\n",
        "\n",
        "With respect to image classification, we do need to set `remove_unused_columns=False` to prevent the `image` column in our dataset to be removed, since it is the one being used to create our `pixel_values` inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:51.927945Z",
          "iopub.status.busy": "2023-12-14T19:33:51.927677Z",
          "iopub.status.idle": "2023-12-14T19:33:52.000951Z",
          "shell.execute_reply": "2023-12-14T19:33:52.000016Z",
          "shell.execute_reply.started": "2023-12-14T19:33:51.927920Z"
        },
        "id": "eBAqo4EmS9M1"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./image\",\n",
        "    per_device_train_batch_size=16,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=3e-4,\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=True,\n",
        "    report_to='tensorboard',\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:52.002416Z",
          "iopub.status.busy": "2023-12-14T19:33:52.002104Z",
          "iopub.status.idle": "2023-12-14T19:33:54.709205Z",
          "shell.execute_reply": "2023-12-14T19:33:54.708426Z",
          "shell.execute_reply.started": "2023-12-14T19:33:52.002388Z"
        },
        "id": "LrbrpWOeS9M1"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collate_fn,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=processed_dataset[\"train\"],\n",
        "    eval_dataset=processed_dataset[\"validation\"],\n",
        "    tokenizer=processor\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:33:54.710570Z",
          "iopub.status.busy": "2023-12-14T19:33:54.710286Z",
          "iopub.status.idle": "2023-12-14T19:45:09.552125Z",
          "shell.execute_reply": "2023-12-14T19:45:09.550924Z",
          "shell.execute_reply.started": "2023-12-14T19:33:54.710543Z"
        },
        "id": "-ADaMen8S9M1"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj0fJp5mS9M4"
      },
      "source": [
        "### evaluating on our test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:45:09.553693Z",
          "iopub.status.busy": "2023-12-14T19:45:09.553414Z",
          "iopub.status.idle": "2023-12-14T19:45:23.155367Z",
          "shell.execute_reply": "2023-12-14T19:45:23.154476Z",
          "shell.execute_reply.started": "2023-12-14T19:45:09.553667Z"
        },
        "id": "xyGJj2GqS9M4"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(processed_dataset['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPPiUKHKS9M4"
      },
      "source": [
        "### let's look at some of the predictions made by our new model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:45:36.873286Z",
          "iopub.status.busy": "2023-12-14T19:45:36.872884Z",
          "iopub.status.idle": "2023-12-14T19:45:41.256480Z",
          "shell.execute_reply": "2023-12-14T19:45:41.255296Z",
          "shell.execute_reply.started": "2023-12-14T19:45:36.873254Z"
        },
        "id": "AdVTA41FS9M4"
      },
      "outputs": [],
      "source": [
        "def show_predictions(rows,cols):\n",
        "    samples = our_dataset['test'].shuffle().select(np.arange(rows*cols))\n",
        "    processed_samples = samples.with_transform(transforms)\n",
        "    predictions = trainer.predict(processed_samples).predictions.argmax(axis=1) # predicted labels from logits\n",
        "    fig = plt.figure(figsize=(cols*4,rows*4))\n",
        "    for i in range(rows*cols):\n",
        "        img = samples[i]['image']\n",
        "        prediction = predictions[i]\n",
        "        label = f\"label: {samples[i]['label']}\\npredicted: {id2label[prediction]}\"\n",
        "        fig.add_subplot(rows,cols,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "\n",
        "show_predictions(rows=5,cols=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCUInx_bS9M4"
      },
      "source": [
        "### Our model works really well! Let's save it and also push it to Hugging Face model hub!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:45:41.258018Z",
          "iopub.status.busy": "2023-12-14T19:45:41.257713Z",
          "iopub.status.idle": "2023-12-14T19:45:41.262693Z",
          "shell.execute_reply": "2023-12-14T19:45:41.261829Z",
          "shell.execute_reply.started": "2023-12-14T19:45:41.257990Z"
        },
        "id": "AYvNEkjrS9M5"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"finetuned_from\": model.config._name_or_path,\n",
        "    \"dataset\": 'pcuenq/oxford-pets',\n",
        "    \"tasks\": \"image-classification\",\n",
        "    \"tags\": ['image-classification'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T19:45:41.264051Z",
          "iopub.status.busy": "2023-12-14T19:45:41.263782Z",
          "iopub.status.idle": "2023-12-14T19:45:47.793435Z",
          "shell.execute_reply": "2023-12-14T19:45:47.792465Z",
          "shell.execute_reply.started": "2023-12-14T19:45:41.264026Z"
        },
        "id": "6z-hQMqvS9M5"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()\n",
        "trainer.push_to_hub('🐕️🐈️', **kwargs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}